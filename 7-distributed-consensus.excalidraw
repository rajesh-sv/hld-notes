{
  "type": "excalidraw",
  "version": 2,
  "source": "https://excalidraw.com",
  "elements": [
    {
      "id": "no6D27ceyWmOY7gHPId1K",
      "type": "text",
      "x": 310.55555555555566,
      "y": 163.78512720908577,
      "width": 1097.933349609375,
      "height": 1625,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "index": "bFi",
      "roundness": null,
      "seed": 954545441,
      "version": 719,
      "versionNonce": 1579598625,
      "isDeleted": false,
      "boundElements": null,
      "updated": 1746425472177,
      "link": null,
      "locked": false,
      "text": "Distributed Consensus Algorithms\n1. Raft: \n* Easier to understand and implement than alternatives like Paxos.\n* Primary goal is to manage a replicated log across a cluster of nodes, ensuring that all nodes \n  agree on the sequence of operations (log entries) even if some nodes fail.\n* Raft uses a strong leader approach. A single leader manages the replicated log. If the leader\n  fails, the remaining nodes elect a new leader using a randomized timeout mechanism \n  to avoid split votes. Consensus is achieved when a quorum of nodes agree on log entries proposed \n  by the leader. This ensures consistency and fault tolerance for distributed systems.\n* Terms in Raft: Terms act as a logical clock. Each term begins with a leader election. If an election\n   fails (e.g., split vote), the term ends, and a new term (with an incremented number) begins with a \n   new election.\n\nLeader Election:\n1. When a Follower times out waiting for a Leader's heartbeat, it becomes a Candidate, increments \n   the current term, votes for itself, and requests votes from other servers.\n2. At this point, the other nodes will be informed that an election is ongoing:\n        * If the candidate term number is higher than the local term number, the local node will \n          become a follower (even the current leader) and change their local term number to the \n          candidate term number\n        * If the candidate log is more up to date than the local log and the node hasn’t voted \n          for any other candidate this term, the node will will vote for the candidate\n        * Else, the node does not vote for the candidate\n2. If a Candidate receives votes from a quorum of the nodes in the cluster for that term, it \n   becomes the new Leader.\n3. If it receives a message from a valid Leader in the same or higher term, it reverts to being \n   a Follower.\n4. If the election times out (split vote), a new election starts in a new term.\n\nLog Replication/Broadcasting Messages:\n1. Once a Leader is elected, it accepts client writes.\n2. It appends each write as a new entry to its local log.\n3. It sends ReplicateLog messages to Followers to replicate the entry.\n4. An entry is considered committed once it has been successfully replicated on a quorum of servers.\n5. Once committed, the Leader applies the write to its state machine and notifies Followers so they \n   can apply it too.\n\nRaft Invariant:\nIf the logs on two replicas have the same term number at the same index in the log, they MUST be \nthe same up to and including that index.\n\nWorking of ReplicateLog Function:\n1. Leader Sends Updates: \nThe leader keeps track of which log entries it thinks each follower already has. It sends any new entries \nthat follower needs. Along with the new entries, it includes the index and term number of the last entry \nit believes the follower already has.\n\n2. Follower Checks Consistency: \nThe follower receives the new entries and the info about the last shared entry. It checks its own log at \nthat specific index.\n    If Match: If the term number in its own log at that index matches what the leader sent, the follower \n    knows its log is consistent up to that point. It deletes any conflicting entries it might have after that \n    point and adds the new entries from the leader. It then tells the leader \"OK\".\n    If No Match: If the term numbers don't match (or the follower is in a newer term), the follower's log is \n    inconsistent with the leader's at that point. It rejects the new entries and tells the leader \"FAIL\".\n\n3. Leader Reacts:\n    On \"OK\": The leader marks that the follower has successfully received those entries. When a quorum of \n    followers have said \"OK\" for a specific entry, the leader considers that entry committed (safely replicated). \n    It then informs followers about committed entries so they can apply them.\n    On \"FAIL\": The leader realizes its assumption about what the follower had was wrong. It needs to find the \n    last point where their logs do match. So, it \"backs up\" – it will try again, sending entries starting from an \n    earlier point in its log to that specific follower. This process continues until it finds the matching point and \n    can successfully add the new entries. (If the failure was because the follower is in a higher term, \n    the leader steps down).",
      "fontSize": 20,
      "fontFamily": 5,
      "textAlign": "left",
      "verticalAlign": "top",
      "containerId": null,
      "originalText": "Distributed Consensus Algorithms\n1. Raft: \n* Easier to understand and implement than alternatives like Paxos.\n* Primary goal is to manage a replicated log across a cluster of nodes, ensuring that all nodes \n  agree on the sequence of operations (log entries) even if some nodes fail.\n* Raft uses a strong leader approach. A single leader manages the replicated log. If the leader\n  fails, the remaining nodes elect a new leader using a randomized timeout mechanism \n  to avoid split votes. Consensus is achieved when a quorum of nodes agree on log entries proposed \n  by the leader. This ensures consistency and fault tolerance for distributed systems.\n* Terms in Raft: Terms act as a logical clock. Each term begins with a leader election. If an election\n   fails (e.g., split vote), the term ends, and a new term (with an incremented number) begins with a \n   new election.\n\nLeader Election:\n1. When a Follower times out waiting for a Leader's heartbeat, it becomes a Candidate, increments \n   the current term, votes for itself, and requests votes from other servers.\n2. At this point, the other nodes will be informed that an election is ongoing:\n        * If the candidate term number is higher than the local term number, the local node will \n          become a follower (even the current leader) and change their local term number to the \n          candidate term number\n        * If the candidate log is more up to date than the local log and the node hasn’t voted \n          for any other candidate this term, the node will will vote for the candidate\n        * Else, the node does not vote for the candidate\n2. If a Candidate receives votes from a quorum of the nodes in the cluster for that term, it \n   becomes the new Leader.\n3. If it receives a message from a valid Leader in the same or higher term, it reverts to being \n   a Follower.\n4. If the election times out (split vote), a new election starts in a new term.\n\nLog Replication/Broadcasting Messages:\n1. Once a Leader is elected, it accepts client writes.\n2. It appends each write as a new entry to its local log.\n3. It sends ReplicateLog messages to Followers to replicate the entry.\n4. An entry is considered committed once it has been successfully replicated on a quorum of servers.\n5. Once committed, the Leader applies the write to its state machine and notifies Followers so they \n   can apply it too.\n\nRaft Invariant:\nIf the logs on two replicas have the same term number at the same index in the log, they MUST be \nthe same up to and including that index.\n\nWorking of ReplicateLog Function:\n1. Leader Sends Updates: \nThe leader keeps track of which log entries it thinks each follower already has. It sends any new entries \nthat follower needs. Along with the new entries, it includes the index and term number of the last entry \nit believes the follower already has.\n\n2. Follower Checks Consistency: \nThe follower receives the new entries and the info about the last shared entry. It checks its own log at \nthat specific index.\n    If Match: If the term number in its own log at that index matches what the leader sent, the follower \n    knows its log is consistent up to that point. It deletes any conflicting entries it might have after that \n    point and adds the new entries from the leader. It then tells the leader \"OK\".\n    If No Match: If the term numbers don't match (or the follower is in a newer term), the follower's log is \n    inconsistent with the leader's at that point. It rejects the new entries and tells the leader \"FAIL\".\n\n3. Leader Reacts:\n    On \"OK\": The leader marks that the follower has successfully received those entries. When a quorum of \n    followers have said \"OK\" for a specific entry, the leader considers that entry committed (safely replicated). \n    It then informs followers about committed entries so they can apply them.\n    On \"FAIL\": The leader realizes its assumption about what the follower had was wrong. It needs to find the \n    last point where their logs do match. So, it \"backs up\" – it will try again, sending entries starting from an \n    earlier point in its log to that specific follower. This process continues until it finds the matching point and \n    can successfully add the new entries. (If the failure was because the follower is in a higher term, \n    the leader steps down).",
      "autoResize": true,
      "lineHeight": 1.25
    },
    {
      "id": "brLrupkMc3YWXoM6gvm4W",
      "type": "line",
      "x": 1431.0476190476195,
      "y": 164.5555555555557,
      "width": 0,
      "height": 1638.3333333333335,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 4,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "index": "bFj",
      "roundness": {
        "type": 2
      },
      "seed": 1263198721,
      "version": 217,
      "versionNonce": 2038675201,
      "isDeleted": false,
      "boundElements": null,
      "updated": 1746425472178,
      "link": null,
      "locked": false,
      "points": [
        [
          0,
          0
        ],
        [
          0,
          1638.3333333333335
        ]
      ],
      "lastCommittedPoint": null,
      "startBinding": null,
      "endBinding": null,
      "startArrowhead": null,
      "endArrowhead": null
    },
    {
      "id": "4ULf6j85okqtqQvgk8WIZ",
      "type": "text",
      "x": 1470.414277576265,
      "y": 163.78512720908577,
      "width": 92.13333129882812,
      "height": 25,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "index": "bFk",
      "roundness": null,
      "seed": 986691681,
      "version": 847,
      "versionNonce": 642490433,
      "isDeleted": false,
      "boundElements": [],
      "updated": 1746425490570,
      "link": null,
      "locked": false,
      "text": "2. Paxos:",
      "fontSize": 20,
      "fontFamily": 5,
      "textAlign": "left",
      "verticalAlign": "top",
      "containerId": null,
      "originalText": "2. Paxos:",
      "autoResize": true,
      "lineHeight": 1.25
    }
  ],
  "appState": {
    "gridSize": 20,
    "gridStep": 5,
    "gridModeEnabled": false,
    "viewBackgroundColor": "#fffce8"
  },
  "files": {}
}